{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sambosis/NLP-Text-Generation/blob/main/Copy_of_firstcodegenipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "#apt install openai_secret_manager\n",
        "sysmess = \"You are a helpful file generator. your message back to me should be in the file format requested by the user. So if I ask you to write python code your message to me should only be what would be included in a working python file. All non code would need to be in the form of comments. If you are asked to create a text file that has a list then your message should only contain the items in the list\"\n",
        "userremind = \"When you are asked to generate code you are only allowed to respond in the form of a valid python file. Anything besides code should start with a # Make sure that your reponse sent back will create a valid python file with no other works or charaters. this needs to be true of your response if i try to write it to a file without any further edits\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUlCIU_9v4yq",
        "outputId": "58d720d7-569c-4b8a-f72a-0a36605aa8c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, charset-normalizer, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T07WnoxUvE-V",
        "outputId": "a9830bee-c4ad-4efb-e764-769a47a01fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter some text: generate code to create silly nick names for Camden\n",
            "# Here's some code to generate silly nicknames for Camden\n",
            "\n",
            "import random\n",
            "\n",
            "# List of possible nicknames\n",
            "nicknames = ['Cammy', 'Camster', 'Cam-a-lam-a-ding-dong', 'Cam-Slam', 'Cam-bone', 'Cam-a-roonie']\n",
            "\n",
            "# Randomly select a nickname for Camden\n",
            "print(random.choice(nicknames))\n",
            "Response saved to dog0.py\n",
            "Cam-bone\n",
            "Please enter some text: generate code to create 19 strong passwords and write them to a file named \"passwirdds.txt\"\n",
            "# importing the required libraries\n",
            "import string\n",
            "import random\n",
            "\n",
            "# list of characters to choose from for generating a password\n",
            "characters = string.ascii_letters + string.digits + string.punctuation\n",
            "\n",
            "# generating 19 strong passwords\n",
            "passwords = []\n",
            "for i in range(19):\n",
            "    password = ''\n",
            "    for j in range(16):\n",
            "        password += random.choice(characters)\n",
            "    passwords.append(password)\n",
            "\n",
            "# writing the passwords to a file named \"passwirdds.txt\"\n",
            "with open('passwirdds.txt', 'w') as file:\n",
            "    for password in passwords:\n",
            "        file.write(password + '\\n')\n",
            "Response saved to dog1.py\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# Set up the OpenAI API key\n",
        "openai.api_key = \"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\"\n",
        "sysmess = \"You are a helpful file generator. your message back to me should be in the file format requested by the user. So if I ask you to write python code your response to me should only be what would be included in a working python file. All non code would need to be in the form of comments. If you are asked to create a text file that has a list then your message should only contain the items in the list\"\n",
        "userremind = \"When you are asked to generate code you are only allowed to respond in the form of a valid python file. Anything besides code should start with a # Make sure that your reponse sent back will create a valid python file with no other works or charaters. this needs to be true of your response if i try to write it to a file without any further edits\"\n",
        "# Start a loop that iterates 2 times\n",
        "for i in range(2):\n",
        "    # Ask the user for input\n",
        "    user_input = input(\"Please enter some text: \")\n",
        "    # Make a request to the GPT-3.5-Turbo model with the user input as the prompt\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"system\", \"content\": sysmess},{\"role\": \"user\", \"content\": userremind},\n",
        "                  {\"role\": \"user\", \"content\": user_input}]\n",
        "    )\n",
        "    # Extract the response from the GPT model\n",
        "    gpt_response = response.choices[0].message.content\n",
        "\n",
        "    # Save the response to a file named dog#.py where # is the current iteration of the loop\n",
        "    filename = f\"dog{i}.py\"\n",
        "    print(gpt_response)\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(gpt_response)\n",
        "    print(f\"Response saved to {filename}\")\n",
        "    !python {filename}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GqHDSIZnJ4hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python dog0.py\n"
      ],
      "metadata": {
        "id": "jLCFdYuH7yUJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python dog0.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDOU9VMu6Fp3",
        "outputId": "89b68e82-0cc2-4a03-ac60-de557d947eb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/content/dog0.py\", line 1\n",
            "    Here's the python code for generating a list of prime numbers and writing them to a text file called prime.txt:\n",
            "                                                                                                                   ^\n",
            "SyntaxError: EOL while scanning string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Start a loop that iterates 2 times\n",
        "for i in range(2):\n",
        "    # Ask the user for input\n",
        "    user_input = input(\"Please enter some text: \")\n",
        "    # Make a request to the GPT-3.5-Turbo model with the user input as the prompt\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"system\", \"content\": sysmess},\n",
        "                  {\"role\": \"user\", \"content\": user_input}]\n",
        "    )\n",
        "    # Extract the response from the GPT model\n",
        "    gpt_response = response.choices[0].message.content\n",
        "\n",
        "    # Save the response to a file named dog#.py where # is the current iteration of the loop\n",
        "    filename = f\"dog{i}.py\"\n",
        "    print(gpt_response)\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(gpt_response)\n",
        "    print(f\"Response saved to {filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mBab-icxAg2",
        "outputId": "d1b32cdb-0c87-461f-9cc4-8322c97db377"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter some text: generate python code that creates a list of prime numbers and then writes them to a file called prime.txt\n",
            "```python\n",
            "def is_prime(num):\n",
            "    if num == 2 or num == 3:\n",
            "        return True\n",
            "    if num < 2 or num % 2 == 0:\n",
            "        return False        \n",
            "    for i in range(3, int(num ** 0.5) + 1, 2):\n",
            "        if num % i == 0:\n",
            "            return False\n",
            "    return True\n",
            "\n",
            "# generate list of prime numbers\n",
            "primes = [2]\n",
            "\n",
            "for number in range(3, 1000):\n",
            "    if is_prime(number):\n",
            "        primes.append(number)\n",
            "\n",
            "# write primes to file\n",
            "with open('prime.txt', 'w') as file:\n",
            "    for prime in primes:\n",
            "        file.write(str(prime) + '\\n')\n",
            "```\n",
            "\n",
            "This code defines `is_prime` function to determine whether a number is prime or not. Then, it generates a list of prime numbers from 2 to 1000 using `is_prime`. Finally, it writes the list of prime numbers to a file called `prime.txt`.\n",
            "Response saved to dog0.py\n",
            "Please enter some text: generate python code that creates a list of prime numbers. Please remember to start any line that is not code with a # so that it will be a comment.\n",
            "# Python code to generate a list of prime numbers\n",
            "# Define the minimum and maximum range of the prime numbers\n",
            "start = 2\n",
            "limit = 100\n",
            "\n",
            "# Define a function to check if the number is prime or not\n",
            "def is_prime(num):\n",
            "    if num < 2:\n",
            "        return False\n",
            "    for i in range(2,num):\n",
            "        if num%i ==0:\n",
            "            return False\n",
            "    return True\n",
            "\n",
            "# Use a list comprehension to generate the list of prime numbers\n",
            "prime_list = [x for x in range(start,limit) if is_prime(x)]\n",
            "\n",
            "# Print the list of prime numbers\n",
            "print(prime_list)\n",
            "Response saved to dog1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set up the OpenAI API key\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# Read the content of speechPrimer.txt\n",
        "with open(\"speechPrimer.txt\", \"r\") as f:\n",
        "    speech_primer = f.read()\n",
        "\n",
        "# Loop 5 times\n",
        "for i in range(5):\n",
        "    # Make the speech more bill_clinton and technical\n",
        "    formal_request = f\"Please rewrite the following speech using more formal and technical language:\\n\\n{speech_primer}\"\n",
        "    formal_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": formal_request}])\n",
        "    formal_speech = formal_response.choices[0].message.content #.text.strip()\n",
        "    \n",
        "    # Save the formal speech to speechFormal#.txt\n",
        "    with open(f\"speechFormal{i}.txt\", \"w\") as f:\n",
        "        f.write(formal_speech)\n",
        "\n",
        "    # Rewrite the speech in the style of Bill Clinton\n",
        "    bill_clinton_request = f\"Please rewrite the following speech in the style of Bill Clinton:\\n\\n{formal_speech}\"\n",
        "    bill_clinton_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": bill_clinton_request}])\n",
        "    bill_clinton_speech = bill_clinton_response.choices[0].message.content #.text.strip()\n",
        "    \n",
        "\n",
        "    # Save the Bill Clinton speech to speechBC#.txt\n",
        "    with open(f\"speechBC{i}.txt\", \"w\") as f:\n",
        "        f.write(bill_clinton_speech)\n",
        "\n",
        "    # Make the speech more concise\n",
        "    concise_request = f\"Please make the following speech more concise:\\n\\n{bill_clinton_speech}\"\n",
        "    concise_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": concise_request}])\n",
        "    concise_speech = concise_response.choices[0].message.content #.text.strip()\n",
        "    \n",
        "\n",
        "    # Save the concise speech to speechConcise#.txt\n",
        "    with open(f\"speechConcise{i}.txt\", \"w\") as f:\n",
        "        f.write(concise_speech)\n",
        "\n",
        "    # Set the concise speech as the primer for the next iteration\n",
        "    speech_primer = concise_speech\n"
      ],
      "metadata": {
        "id": "sAf0RjRZKH-G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': 'Sample file.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "metadata": {
        "id": "Gq3zpWlaVSNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"*.txt\")"
      ],
      "metadata": {
        "id": "TRKGOuD1WAk7",
        "outputId": "4102b6a1-c7a6-4687-eaa6-a298a9b9c917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c5e3463918f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: *.txt"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r my_files.zip /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRAm7J0DL2Pg",
        "outputId": "710a56cf-c16b-4fda-bcba-ceca17500e43"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning files ..................\n",
            "\n",
            "\n",
            "zip error: Interrupted (aborting)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Ods0aCAXLN5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}